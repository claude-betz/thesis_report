\chapter{Theoretical Framework}\label{chapter_theoretical_framework}

This Chapter aims to provide a comprehensive treatment of the theory necessary
for the implementation of the Overall MOT System. This is in line with the
objectives of the study outlined in Section~\ref{introduction_objectives} and
the research direction determined in reviewing the relevant literature in
Chapter~\ref{chapter_literature_review}.

Sections~\ref{theoretical_framework_mean_shift} and
Section~\ref{theoretical_framework_mean_shift_tracker} draw heavily from the
work and presentations of the theory by \cite{Comaniciu2002},
\cite{Comaniciu2003}, \cite{Shah2011}. They do however take the liberty in
making some changes to the notation and order of presentation, while adding some
visual illustrations and context to certain steps. 

\section{Mean Shift} \label{theoretical_framework_mean_shift}
The Mean Shift Method is an algorithm that is capable of finding the modes of a 
non-parametric distribution by use of samples of the unknown underlying distribution. 

\section{Mean Shift Tracker} \label{theoretical_framework_mean_shift_tracker}
As summarised in Section~\ref{literature_review_mean_shift}, the Mean Shift Tracker was
first proposed by Commaniciu et al. It is addresses the
visual tracking problem of Target Representation and Localisation.

The idea of this tracker is that spatially masking an object with an
isotropic kernel allows for the definition of a spatially-smooth similarity
function relating a target and potential candidate model in a particular feature
space. This smooth similarity lends itself to gradient-based optimization,
thereby enabling efficient target localisation in subsequent frames
\cite{Comaniciu2003}.

A description of theory underlying the Mean Shift Tracker follows:

\subsection{Model Representation}
To represent a particular target or candidate Model, a suitable feature space
must be chosen. This choice could be anything from grayscale intensity, RGB
intensity or Texture of the particular object. Objects are geometrically described 
as elliptical sub-domains $\mathbf{D}$ of a frame, with dimensions $h_x$ and
$h_y$, centered at pixel location $\mathbf{c}=(x,y)$ within the frame. (see
Figure~\ref{fig:epanechnikov_kernel} for an illustration)

Target and candidate models are defined as pdf's within the chosen feature
space defined over $\mathbf{D}$. In the initial frame, $\mathbf{f}_k$, a target
model of the object to be tracked located at $\mathbf{c_0}$ is defined by it's
pdf, $\hat{q}(\mathbf{c_0})$. In the subsequent frame, $\mathbf{f}_{k+1}$, a
candidate model is defined with pdf $\hat{p}(\mathbf{c_0})$ starting at the last
known object position $\mathbf{c_0}$. 

Both pdf's $\hat{q}(\mathbf{c_0})$ and $\hat{p}(\mathbf{c_0})$ are estimated from
their respective frames $\mathbf{f}_k$ and $\mathbf{f}_{k+1}$ using $m$-bin
weighted histograms within the relevant feature space. The weighting is achieved
by use of a Kernel. 

\subsection{Kernel Function}
A Kernel is a weighting function employed in non-parametric density estimation.
The recommended kernel function for the mean shift tracker is that of the
Epanechnikov kernel \cite{Comaniciu2002}.
The Epanechnikov Kernel has the following general equation:
\begin{equation}
    \kappa(x)=
    \begin{cases}
        \frac{1}{2c_d}(d+2)(1-x), & |x|<1 \\
        0, & \text{otherwise}
    \end{cases}
\end{equation}
where:
\begin{itemize}
   \item $d$: the dimensions of the kernel
   \item $c_d$: the area of a unit circle in the dimension $d$
   \item $x$: the square of the Euclidian distance of the normalized pixel in
       $\mathbf{n_x}$
\end{itemize}

Of interest is the 2D variant of this equation given that the spatial smoothing
is occurring in the 2D $(x,y)$ pixel plane. Thus we choose $d=2$ and $c_d=\pi$.
As the kernel profile does not vary for a particular region of interest, it is
computationally convenient to pre-calculate its values for use in the subsequent
derivation of the histogram.

The calculation of the Epanechnikov Kernel Matrix for a particular $\mathbf{D}$ is
illustrated in Figure~\ref{fig:epanechnikov_kernel}.

\Figure[width=0.8\columnwidth]{Illustration of Epanechnikov Matrix Derivation\label{fig:epanechnikov_kernel}}{design_epanechnikov_kernel_illustration}

The pixels in the elliptical mask of the target/candidate are normalized to a unit
circle by scaling the ellipse by $h_y$ and $h_x$ (which are the major and minor
axes size of the ellipse). Each pixel is then assigned a weight according to the
value of the 2D Epanechnikov Kernel profile for said pixel's normalized euclidean
distance from the unit circle centre as illustrated in Figure~\ref{fig:epanechnikov_kernel}.

These weights derived from the kernel profile are subsequently used to scale
pixel counts when creating m-bin histogram. The monotonically decreasing Kernel
assigns higher weight to pixels at the centre of $\mathbf{D}$ while giving lower
weighting to pixels further away from the domain center $\mathbf{c}$. 
This is desirable because not only does it enable the development of a spatially
smooth similarity function as addressed in Section~\ref{maximising_bhat} but it
also encodes into our model robustness to the effects of occlusions at the
periphery of the object domain.

\subsection{pdf development}
Computing the pdf then occurs according to the following equation:
\begin{equation}\label{eqn:mean_shift_histogram}
    \text{pdf}(u)=C\sum_{i=1}^{n_x}\kappa({\parallel{\mathbf{x_i}^*}-{\mathbf{c_0}^*}\parallel}^2)\delta[b(\mathbf{x_i}^*)-u]    
\end{equation}
\begin{equation}\label{eqn:histogram_normalisation}
    C=\frac{1}{\sum_{i=1}^{n_x}\kappa({\parallel\mathbf{x_i}^*\parallel}^2)}
\end{equation}
where:
\begin{itemize}
    \item $\mathbf{x_i}^*$: normalised pixel 
    \item $n_x$: normalised pixel domain.
    \item $\parallel{\mathbf{x_i}}^*-{\mathbf{x_0}}^*\parallel$: The euclidean
        norm between $\mathbf{x_i}^*$ and ${\mathbf{x_0}}^*$ squared which
        reduces to $\parallel{\mathbf{x_i}}^*\parallel$ for $\mathbf{c_0} = 0$. 
    \item $\kappa({\parallel{\mathbf{x_i}}^*\parallel}^2)$: Kernel function that
        defining weights based on $\parallel{\mathbf{x_i}}^*\parallel^2$.
    \item $b({\mathbf{x_i}}^*)$: A function which maps the normalized pixel
        values in $\mathbf{n_x}$ to their RGB pixel value in $\mathbf{D}$.
    \item $\delta[b({\mathbf{x_i}}^*)-u]$: Abstraction to say only evaluate for bin u.
    \item $C$: Normalisation constant to ensure histogram satisfies Equation~\ref{eqn:histogram_normalisation}.
\end{itemize}

Depending on the number of features used computational complexity of calculating
the histogram and space needed for storing the histogram goes up by a factor of
$m$, as we are increasing the dimensionality of our feature space by 1 for each
additional feature thus incrementing the size by a factor of $m$-bins.

The models for the target and candidate are summarised below:
$$\text{target model: } \hat{q}(\mathbf{c_0})=\{\hat{q}_u(\mathbf{c_0})\}_{u=1,...,m}$$
$$\text{candidate model: } \hat{p}(\mathbf{c_i})=\{\hat{p}_u(\mathbf{c_i})\}_{u=1,...,m}$$

All model/candidate histograms are normalized. Therefore, a general m-bin
histogram, $\hat{p}(\mathbf{c_i})$ defined over spacial sub-domain, $\mathbf{D}$
within a frame $\mathbf{f}_k$, satisfies the following normalisation condition:
$$\sum_{u=1}^{m}\hat{p}_u = 1$$

\subsection{Similarity Measure}
Given a target model's pdf $\hat{q}(\mathbf{c_0})$, and a candidate pdf,
$\hat{p}(\mathbf{c_i})$, in a subsequent frame.  The function $\rho$ returns a
metric describing how strongly a target $\hat{p}(\mathbf{c_i})$ resembles
$\hat{q}(\mathbf{c_0})$ i.e.
$\rho_i \equiv \rho[\hat{q}(\mathbf{c_0}),\hat{p}(\mathbf{c_i})]$


As per \cite{Comaniciu2003} we make use of the Bhattacharyya coefficient, $BC$ as our
measure of similarity measure $\rho$ between the target and candidate pdfs. The
Bhattacharyya coefficient is defined by the following equation:
\begin{equation}\label{eqn:bhattacharyya}
    BC = \rho[\hat{q}(\mathbf{c_0}),\hat{p}(\mathbf{c_i})]=\sum_{u=1}^{m}\sqrt{\hat{p}_u(\mathbf{c_i})\hat{q}_u(\mathbf{c_0})}
\end{equation}

\subsection{Maximising the Bhattacharyya Coefficient}\label{maximising_bhat}
Since a monotonically decreasing kernel weighting function is applied in the
derivation of our feature histograms, the similarity function $\rho$ defined by the
Bhattacharyya Coefficient is smooth over the (x,y) domain.

As stated, we begin with a target model $\hat{q}(\mathbf{c_0})$ in frame k and a candidate
model at the same location $\hat{p}(c_0)$ in $\mathbf{f}_{k+1}$. We compute
$\rho_0=\rho[\hat{q}(\mathbf{c_0})\hat{p}(\mathbf{c_0})]$ 

Since $\rho$ is spatially smooth, we can apply optimization. This involves
taking the first order Taylor Series approximation of $\rho$ around our initial
estimate $\mathbf{c_0}$. 
\begin{equation}\label{eqn:rho_taylor}
    \rho[\hat{q}(\mathbf{c_0})\hat{p}(\mathbf{c_i})]=\rho[\hat{q}(\mathbf{c_0})\hat{p}(\mathbf{c_0})]+\frac{1}{2}\sum_{i=1}^{m}\hat{p}(\mathbf{c_i})\sqrt{\frac{\hat{q}_u}{\hat{p}_u(\mathbf{c_0})}}
\end{equation}

This is a valid approximation for small changes to $\hat{p}(\mathbf{c_i})$
which usually holds between adjacent frames in the video sequence. 

The first term on the right hand side is a constant, by maximising the second
term 
$$\frac{1}{2}\sum_{i=1}^{m}\hat{p}(\mathbf{c_i})\sqrt{\frac{\hat{q}_u}{\hat{p}_u(\mathbf{c_0})}}$$
We maximise $\rho$ and in doing so we locate our object in frame k+1.

By substitution of Equation~\ref{eqn:mean_shift_histogram} for $\hat{p}(\mathbf{c_i})$ in
the second term of Equation~\ref{eqn:rho_taylor} it can be observed that is that the
second term is the density estimate of the underlying pdf at center
$\mathbf{c_i}$ in $\mathbf{f}_{k+1}$ with pixels weighted according to the
following equation:

$$\rho_0=\rho[\hat{q}(\mathbf{c_0})=\frac{C}{2}\sum_{i=1}^{m}w_i\kappa({\parallel{\mathbf{x_i}^*}-{\mathbf{c_0}^*}\parallel}^2)$$

\begin{equation}\label{eqn:mean_shift_weights}
    w_i(\mathbf{c_0})=\sum_{u=1}^{m}\sqrt{\frac{\hat{q}_u}{\hat{p}_u(\mathbf{c_0})}}\delta[b(\mathbf{x_i}^*-u)]
\end{equation}

Using the Mean Shift Procedure outlined in Section~\ref{theoretical_framework_mean_shift}, $\rho$ can be maximised thus locating
our object in frame $\mathbf{f}_{k+1}$.

\subsection{The General Algorithm}\label{theoretical_framework_mean_shift_algorithm}
The general algorithm for Mean Shift Tracking between two frames is defined by
flow chart in Figure \ref{fig:mean_shift_tracking_algorithm}. This algorithm follows
the optimized practical implementation expanded on by \cite{Comaniciu2003}. 

\Figure[width=0.75\columnwidth]{Flow Chart of Mean Shift Tracking Algorithm
between two frames $\mathbf{f}_k$ and
$\mathbf{f}_{k+1}$\label{fig:mean_shift_tracking_algorithm}}{design_mean_shift_tracking_algorithm}

The preceding theory for the basis for the implementation of the Mean Shift
Tracker implemented in Chapter~\ref{chapter_implementation}.



