\chapter{Literature Review}\label{chapter_literature_review}
This literature review begins by establishing key definitions necessary for
navigating the literature.
It proceeds to outline a general framework to solving the motion tracking
problem in terms of two approaches of detection and tracking. After outlining
the challenges within the field of motion tracking, it details
the subtasks relevant to these approaches. These subtasks are conveniently expressed as
taxonomies that are elaborated on. The review settles on a subset of approaches
to the motion tracking problem, expressed as kernel based tracking. The
exploration of kernel based tracking methods forms the foundation of this study.

\section{Key Terms}
The field of computer vision is riddled with similar sounding terms whose intent
can get muddled during the discussion of concepts. The purpose of this section
is to establish the intent of these keywords as they are used later in this
review. Detailed below are definitions of important deemed important to the
subsequent presentation of the literature. Some of these words may not be
mentioned, but can provide
context to other terms used.

\textbf{Image Segmentation}: This is the process of partitioning an image into multiple
sets of pixels with the goal of making the image easier to analyse, it typically
involves finding boundary lines of objects. 

\textbf{Motion Segmentation}: Motion segmentation refers to the labelling of pixels that
are associated with each independently moving 3D object in sequence of images
that can feature multiple motions.~\cite{Tekalp2014}

\textbf{Object Recognition}: This a method by which, given an image, the objects within
said image are detected and classified as one of a set of predefined object
category i.e.\ ``What object (s) are in this frame?''

\textbf{Object Detection}: Object detection can be seen as targeted recognition, it deals
with finding instances of objects within a given image or video frame, this
technique usually makes use of extracted features and learning algorithms to
recognize instances of an object category i.e. ``Where is this particular
object in this frame?''

\textbf{Object Classification}: This is a broader treatment than detection, where a
system is not only able to identify objects within images but can differentiate
between and label different classes of objects within the image. 

\textbf{Optical Flow}: This refers to the pattern of apparent motion of objects, surfaces and
edges in a visual scene caused by the relative motion between an observer and a
scene. Optic flow fields can be used to structure or segment a scene~\cite{Forsyth2012}.

\textbf{Object Tracking}: Object tracking also known as Video Tracking refers to the use
of sensor measurements to determine the location, path and characteristics of
objects of interest~\cite{Challa2011}.
 
\textbf{Motion Estimation}: A fundamental problem in video processing that is concerned
with determining motion vectors that describe the transformation of one 2D
image to another over time~\cite{Tekalp2014}.

NOTE:\@
tracking data to another object for example in animation. Or as it is used in the
case of this paper Video/Object Tracking.

\section{Approaches to Motion Tracking}\label{literature_review_general_approach}
The problem of isolating moving objects of interest from a scene can
be categorised under the branch of computer vision known as motion
tracking.

The approaches to tracking objects of interest can be classified broadly in two ways:
\begin{itemize}
    \item \textbf{Object Detection}: Assume that there is only one object
        of interest in each frame, $\mathbf{f}_k$ of an image sequence, and that
        there exists a reliable detector for the object of interest, that can
        return it's location within a particular frame of interest. In this case, the
        tracking problem can be reduced to applying the detector to each
        subsequent $\mathbf{f}_k$ of the image sequence
        $\{\mathbf{f}_{k+1},\ldots,\mathbf{f}_{k+n}\}$ and connecting each of the
        $n$ detector responses to form a track~\cite{Forsyth2012}.

        Certain situations lend themselves well to this approach. One could
        imagine that an overhead camera in a game of billiards could easily track the
        position of the 8-ball by searching each video frame for the colour black, as
        this colour differs significantly from the green felt, and the colour of the
        other balls. However, many practical applications cannot assume reliable
        detection or single objects of interest. Referring back to the above example,
        difficulty may arise if a player is wearing a long sleeved black shirt as the
        detector would interpret this as the ball, such a scenario may require more
        sophistication in the design of the detector.

    \item \textbf{Motion Tracking}: Tracking is based on the tendency for an object's
        appearance to be temporally similar and exhibit coherence in motion
        between successive frames, $\mathbf{f}_k$ and $\mathbf{f}_{k+1}$ in an
        image sequence. Given a model of an object, as well a domain within
        $\mathbf{f}_k$ in which the object of interest is located. The motion
        model can be used to search for the model in the domain of interest
        within $\mathbf{f}_{k+1}$.  This is approach differs from tracking by
        detection, as it leverages dynamic inter frame information from
        $\mathbf{f}_k$ to locate the object within $\mathbf{f}_{k+1}$.
\end{itemize}

\section{Challenges to Motion Tracking}\label{literature_review_challenges}
Addressed here are several challenges faced by the various approaches to the to
solve the tasks of object detection and motion tracking. These challenges can
result in degradation or worse failure of a particular motion tracking
implementation. Knowledge of them will be necessary choosing which
approaches to focus on within this study, in line with the objectives outlined
in Section~\ref{introduction_objectives}. 

The challenges are conveniently expressed in
Table~\ref{tbl:computer_vision_challenges}. Illustrations of these challenges
are presented in Chapter~\ref{chapter_results} where they are used to assess the
performance of the implemented motion tracking approaches. These outlined challenges
are often termed \textit{appearance changes} within the
literature~\cite{Li2013}. 

\newpage
\begin{longtable}{p{5cm}  p{8cm}}
    \hline
    \textbf{Challenge} & \textbf{Description} \\ 
    \hline\hline    
    1. Occlusion
    & 
    Objects of interest may only be partially visible in a
    given frame, ideally we want an algorithm to still detect or
    track an object despite this.
    \\ \bottomrule
    
    2. Illumination
    &
    Algorithm performance can be significantly degraded by changes
    in lighting, if their implementation does not take this into
    account.
    \\ \bottomrule
    
    3. Ego Motion
    &
    If image sequences are not recorded by a stationary observer,
    the camera motion has to be accounted for by the algorithm.
    \\ \bottomrule
    
    4. Deformation
    &
    between frame's. For example, observing a bird flying. In this
    case an algorithm may fail if it assumes a consistent shape for
    the object of interest.
    \\ \bottomrule

    5. Orientation
    &
    Objects look different according to their orientation relative
    to the camera.
    \\ \bottomrule

    6. Scale
    &
    An object of interest may change it's scale within an image
    sequence, depending on whether it is moving away from or towards
    the observer.
    \\ \bottomrule

    7. Speed 
    &
    Many algorithms operates on the assumption of small
    changes of the position and appearance of an object between
    subsequent frames. An object moving at a high enough velocity
    affect the performance of algorithms that are not designed to
    deal with this.
    \\ \bottomrule
  
    8. Track Overlap
    &
    This is a situation in which two objects in motion cross paths, it can lead
    to occlusion of the object of interest depending on their proximity to the
    observer of the scene.
    \\ \bottomrule

    \caption{Table illustrating computer vision challenges}
\end{longtable}\label{tbl:computer_vision_challenges}
\newpage

\section{A General Motion Tracking Framework}\label{literature_review_framework}
Among the various surveys of the approaches to motion tracking, Porikli and
Yilmaz~\cite{Porikli2012} stand out in defining a sufficiently general yet comprehensive
framework that details the fundamentals of video analysis based on detection
and tracking. 

Their proposed framework consists of three stages
\begin{itemize}
    \item \textbf{Detection}: Identification and localisation of objects to
        track in an initial frame.
    \item \textbf{Modelling}: Representation of detected objects.
    \item \textbf{Tracking}: Tracking in subsequent frames based on the chosen
        model.
\end{itemize}

These three stages and the various approaches to each stage are subsequently addressed.

\section{Object Detection}\label{literature_review_object_detection}
Object detection is the initial step to any motion tracking algorithm. It can
either be \textit{change based} or \textit{classification based}. There is an
important to distinction between these two.

In classification based object detection, no temporal information is directly
used. The assumption is that an initial algorithm generates regions of interest
within a frame, this could very well be regions identified by a change detector,
edge detector or a simple sliding window. A representative set of features is
extracted for each region of interest and a comparison to a known model feature
using a similarity measure can determine the likelihood of an object of interest
being present. 
This could be by comparison to a set of template models, or more generally the
output of a trained classifier.

Change based object detection on the other hand leverages temporal differences
between adjacent frames $\mathbf{f}_k$ and $\mathbf{f}_{k+1}$ within an image
sequence to detect changes. This is often termed \textit{motion detection}. 

\subsection{Why motion tracking?}
Given that object detection can be used to track an object by way of repeated
detection, why the emphasis on the concept motion tracking?

Object and there are inherent limitations to tracking based purely on
detection based motion tracking as detection tends to be computationally
expensive. Classification based detection is also limited to objects who's
models are known a priori~\cite{Forsyth2012}.

Change based detection approaches usually exist as part and parcel of motion
tracking approaches. Tracking offer variety approaches that address a lot of the
challenges to the tracking problem outlined in
Section~\ref{literature_review_challenges}.

\subsection{Object detection approaches}
There are various approaches to object detection. Based on taxonomies
in~\cite{Prajapati2015,Shantaiya2013}, 
Figure~\ref{fig:literaturereview_taxonomy_motion_detection} outlines some
approaches to object detection that a motion tracker implementation might take.
These approaches are subsequently elaborated on.

\Figure[width=1\columnwidth]{Taxonomy of object detection approaches}{literaturereview_taxonomy_motion_detection}

\subsection{Manual detection}
This is a straightforward means of object detection. It human interaction with a
particular system to highlight a region of interest containing an object in
a particular frame. This is sometimes used as an initialisation step in some
motion tracking applications. Kernel based motion tracking methods as addressed
in Subsection~\ref{literature_review_kernel}, are sometimes manually
initialised~\cite{Prajapati2015}.

\subsection{Template detection}
Template detection is a simple detection method in which a known object
template $\mathbf{T}$ is searched for within a particular image of interest
$\mathbf{I}$. The problem boils down to a matching of features between
subregions within $\mathbf{I}$ and the known $\mathbf{T}$ to locate the regions
with the highest similarity. Template matching can be fixed or deformable. 

In fixed template matching the comparison between $\mathbf{T}$ and $\mathbf{I}$ is normally
performed via a normalised cross correlation. This method is restricted to
applications in which the target image varies minimally~\cite{Shantaiya2013}.
Deformable templates attempt to account for variation in $\mathbf{I}$ by
parametrising a particular template.

\subsection{Feature detection}
Feature based detection emphasises the modelling of objects in terms of a
standardised set of features. One or more representative features are extracted
from objects of interest. Objects of interest are then modelled based on this
feature set.
This approach to detection can be thought of an intermediate step between
Template and Classifier detection. Often objects are initially specified in
terms of a template from which feature vectors are extracted for feature
detection. In the case of classifier detection, classifiers are are usually
trained on large data sets of object feature vectors.

\subsection{Classifier detection}
Given a classifier trained on a set of images based on a representative feature
vector, detection within an image can be formulated as a classification problem.
An image of interest is subdivided into small ``object'' regions with some
overlap. A representative feature vector is extracted for each object and the
detections made according to the classifier output for each object. There have
been significant strides within this with the advent of deep learning.
Consequently, Classifier detection has been applied extensively to real time detection
based motion tracking in recent years with the advent of deep
learning~\cite{goturn}.

\subsection{Motion detection}
Motion based detection methods in their basic form hinge upon the thresholding
of the pixel wise difference between adjacent frames in an image
sequence~\cite{Shantaiya2013}. The regions with large differences likely
correspond to objects in motion. There are several extensions to this using
probabilistic models to more accurately model background and foreground objects.

Motion detection has seen large applicability within the video surveillance
problem in which there are large periods with little change to a particular
scene~\cite{Piccardi2004,Mashak2010}.

\section{Object Modelling}\label{literature_review_object_modelling}
Object modelling refers to the process of defining an internal model of
an identified object of interest subsequent tracking. Object modelling can be
broken down into several layers.
\begin{itemize}
    \item \textbf{Model representation}: The spacial region occupied by object within a
        frame.
    \item \textbf{Model descriptor}: Mathematical definition of an object within
        a frame. A descriptor is derived from an object's underlying low-level information over the spacial
        region it occupies defined by the object's representation.
    \item \textbf{Model low-level features}: characteristics inherent to the
        observable pixels in a frame.
\end{itemize}

\subsection{Model representation}
The model representation of an object refers to the parametric or non-parametric
spacial definition of the object within a particular frame. Notable examples of
representations include

\subsubsection{Point and region}
This is an example of a parametrised representation. In a point and region
representation, an object is defined by a centroid and a predefined shape such
as a rectangle or an ellipse.

\subsubsection{Silhouette representation}
This is a more complex non-parametrised representation. Here, the object of
interest is defined by it's silhouette-the shape inscribed by it's outline.

There are yet more complex model representations, some of which further segment
the object of interest into smaller subregions such as with part-based
representations, for example splitting up an animal object into it's constituent
limbs. The choice of representation is dependent on the problem to which motion
tracking is to be applied~\cite{Porikli2012}.

\subsection{Model descriptor}\label{literature_review_descriptors}
Model descriptors are derived mathematically from the region of interest defined
by the chosen model representation. An effective descriptor is one which allows
for good discrimination between different objects or regions they
describe. Discrimination is characterised by a similarity measure that
facilitates a quantitative assessment of how similar a particular candidate
descriptor in $\mathbf{f}_{k}$ matches it's model descriptor~\cite{Shantaiya2013}.
Some common descriptors are

\subsubsection{Templates}\label{literature_review_template}
Templates are extractions of the pixels in the region of interest of the
underlying frame. They are usually extracted according to a particular
parametric shape, but can also be defined for more complex model representations.

\subsubsection{Density estimates}
Density estimates as model descriptors can be Parametric or Non-Parametric. They
estimate the probability density function based on an underlying low-level
feature within the relevant model representation.
Common low-level features used include; colour-space values, spacial and
temporal intra- and inter-frame derivatives within a given colour-space
etc~\cite{Shantaiya2013}.

\subsection{Model low-level features}
Feature selection is a very relevant step in the development of computer vision
applications. The extent to how discriminative a particular feature is is
largely dependent on the scenarios. Hence many solutions employ a
variety of features to encode into the model robustness across multiple
scenarios. The most common visual low-level features are.

\subsubsection{Colour}
In digital images, colours can be represented in one of several colour spaces, the
most common representation is within the RGB (red, green, blue) colour space. In
the RGB colour space, each pixel is represented by integer in the range $[0,256)$ 
for each channel in the colour space. e.g $\text{black} = \{0,0,0\}$.

\subsubsection{Texture}
Texture measures the variation in intensity of a region within a frame. It can
be interpreted as how smooth or rough the surface of the region is.
For example rough surfaces could be characterised by large variations in pixel
values over short distances corresponding to bumps in an object, or low
variation corresponding to a smooth object with a uniform surface~\cite{Porikli2012}

\subsubsection{Optical flow}
Optical flow is the most general approach to motion estimation. It involves
computing an independent estimate of the motion at each pixel location for each
frame in a sequence.
The result of this is a dense field of optical flow vectors for each frame in
the relevant sequence. Each pixel's vector is characterised by an orientation.
It is easy to imagine that clusters of flow vectors of similar magnitude and
direction could correspond to moving objects between two
frames\cite{Szeliski2010}.

\section{Motion Tracking}
Once an object has been detected in an initial frame, $\mathbf{f}_k$ based on the selected
target model, motion tracking is concerned with locating object in subsequent
frames $\mathbf{f}_{k+1}$ to $\mathbf{f}_{k+n}$ within the image sequence. 

The literature states several tracking methods. These can
conveniently be expressed in the following taxonomy outlined in
Figure~\ref{fig:literaturereview_taxonomy_motion_tracking}, that was adapted
from similar presentations in~\cite{Prajapati2015, Patel2013}. The various
approaches are described in terms of the layers to object modelling described in
Section~\ref{literature_review_object_modelling}.

\Figure[width=0.7\columnwidth]{Taxonomy of motion tracking approaches}{literaturereview_taxonomy_motion_tracking}

\subsection{Point tracking}\label{literature_review_point}
As the name suggest, point tracking, represents objects detected in consecutive
frames by a set of points. Association between the different points is based on
their state in the previous frame(s). Therefore, an external detection algorithm
is required to supply the points at each frame in the image sequence.

There are several approaches to this problem such as Kalman filtering or
Multiple hypothesis tracking each of which focus on the estimation of future
states based on past states. This is a complex yet powerful method as it can
make inference about objects that in face of challenges such as complete
occlusion based on past dynamics (state), where other purely appearance based tracker
models might fail~\cite{Shantaiya2013,Prajapati2015}.

\subsection{Kernel tracking}\label{literature_review_kernel}
Kernel based tracking is usually performed by defining a kernel around an object
of interest. A kernel is usually a parametric model representation such as an
ellipse or square, that encompasses the target object. 
Variations between different kernel tracking methods lie in the chosen representations,
descriptors and their underlying low-level features~\cite{Prajapati2015}

\subsubsection{Simple template matching}
Template Matching is a pattern recognition technique in which stored patterns 
are identified within an image. It can be performed at various levels ranging
from a pixel-level to higher level comparisons of average intensity.

It is an operation that aims to determine what elements of a given image match a
specified template of the element of interest. Formally we have a source image,
$I$ in which we would like to obtain matches to an element of interest defined
by a template image $T$~\cite{Brunelli}. 
Given a target template defined in $\mathbf{f}_k$, we can track an object by 
template matching in $\mathbf{f}_{k+1},\ldots,\mathbf{f}_{k+n}$.

\subsubsection{Mean shift tracking}\label{literature_review_mean_shift}
The mean-shift tracking algorithm provides an efficient tracking approach for
target objects modelled by with density estimate descriptors such a colour or
texture histograms. 
Given the location of a detected object in $\mathbf{f}_k$, mean-shift tracking
locates an object in $\mathbf{f}_{k+1}$ by way of a
non parametric gradient ascent procedure of a smooth similarity function around
the last known location of an object~\cite{Comaniciu2003}. This procedure is
extensively presented in Section~\ref{theoretical_framework_mean_shift_tracker}.

\subsection{Silhouette tracking}
Silhouette tracking is one of the approaches to tracking objects based on their
shapes. It is hinges upon the detection of object silhouettes.  This can be done
via edge detection approaches such as Canny edge
detection~\cite{Delprado2013}.

In the case that a detected silhouette has a simple shape, the Hough transform
can be used to detect or track the shape in subsequent frames of the image
sequence. The Hough transform is clustering algorithm in which data samples
“vote” for the most representative feature values in a quantized feature
space~\cite{Tekalp2014}. 

Applied to silhouettes, the Hough Transform parametrises lines and circles of a
detected shape. Similarity is gauged by the use of a threshold, if a candidate
parametrisation lies above the threshold it is considered a
detection~\cite{Delprado2013} There are various extensions to this approach
which allow for more complex silhouettes to detected. 

\section{Framing the study}\label{literature_review}
Following the brief but broad review of the literature relevant to solving the
motion tracking problem, it is necessary to narrow the scope of the study.

Drawing upon the idea that the tracking problem can be solved from a standpoint
of reliable and efficient detection as well as motion tracking as presented in
Section~\ref{literature_review_general_approach}. This study aims to touch upon
both avenues in solving the motion tracking problem.

Working within the defined motion tracking framework defined in
Section~\ref{literature_review_framework}. This study settles on a subset of
detection, modelling and tracking stages to be combined. These choices are made
in line with the motivations of the study outlined in
Chapter~\ref{chapter_introduction}, and factor into the scoping and subsequent user
requirements of the MT System defined in said chapter.

The definition of the detection and modelling stages is usually more flexible,
in that various trackers can be initialised with different detection methods,
and operate of different models. Refining the scope therefore necessitates an initial
selection of the tracking approach(es) to be trialled. 
This study will focus on an investigation into the class of kernel based
trackers. Within this scope we can recursively define the required modelling and
detection stages after an in depth treatment of the two kernel based tracking
approaches that were briefly elaborated on in
Subsection~\ref{literature_review_kernel}. These being simple template matching
and the mean shift algorithm. 


\section{User Interface Design}
User Interface design (UI) is concerned with facilitation of human-machine
interaction on either a hardware or software level.~\cite{wiki:uid,wiki:ui}.



