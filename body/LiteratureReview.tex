\chapter{Literature Review} \label{chapter_literature_review}
This Literature Review is structured as follows: It begins by establishing key
definitions necessary for navigating the literature.

The Review then broadly details the general approach to solving of Motion Tracking
problems. This is followed by a study of the progression of the field,
specifically reviewing prominent “classical” pre-deep learning approaches to the
problem.

\section{Establishing Key Terms}
The field of Computer vision is riddled with similar sounding terms whose intent
can get muddled during the discussion of concepts.  The purpose of this section
is to establish the intent of these keywords as they are used later in this text.

Detailed below are definitions of important terms within the field of computer
vision, some of which are used rather loosely within the literature or are
despite seeming interchangeable may refer to different concepts. 

Feature Detection:

Image Segmentation: This is the process of partitioning an image into multiple
sets of pixels with the goal of making the image easier to analyse, it typically
involves finding boundary lines of objects. 

Motion Segmentation: Motion Segmentation refers to the labelling of pixels that
are associated with each independently moving 3D object in sequence of images
that can feature multiple motions.~\cite{Tekalp2014}

Object Recognition: This a method by which Given an image, the objects within
said image are detected and classified as one of a set of predefined Object
Category.  I.e. “What Object(s) are in this frame?”

Object Detection: Object Detection can be seen as targeted recognition, it deals
with finding instances of objects within a given image or video frame, this
technique usually makes use of extracted features and learning algorithms to
recognize instances of an object category.  I.e. “Where is this particular
object in this frame?”

Object Classification: This is a broader treatments than Detection, where a
system is not only able to identify objects within images but can differentiate
between and label different classes of objects within the image. 

Optical Flow: refers to the pattern of apparent motion of objects, surfaces and
edges in a visual scene caused by the relative motion between an observer and a
scene. Optic flow fields can be used to structure or segment a scene~\cite{Forsyth2012}.

Optical Flow Segmentation: Refers to the grouping together of optical flow
vectors that are associated with the same 3-D motion or structure. This problem
is identical to motion segmentation provided a dense optical flow field~\cite{Tekalp2014}.

Object Tracking: Object tracking also known as Video Tracking refers to the use
of sensor measurements to determine the location, path and characteristics of
objects of interest~\cite{Challa2011}.
 
Motion Estimation: A fundamental problem in video processing that is concerned
with determining motion vectors that describe the transformation of one 2D
image to another over time~\cite{Tekalp2014}.

NOTE:\@
tracking data to another object.\ e.g.\ animation. Or as it is used in the
case of this paper Video/Object Tracking.

\section{Brief History of Computer Vision and Motion Tracking}
*insert anecdote*

The problem of isolating moving objects of interest from a scene can
be categorised under the branch of Computer Vision known as Motion
Estimation/Tracking.

\section{A General Approach to Motion Tracking}\label{literature_review_general_approach}
The approaches to Motion Tracking are broadly two-fold:
\begin{itemize}
    \item Tracking by Detection:
        Assuming that there is only one object of interest in each frame of
        video, and that there exists a reliable detector for the object of
        interest. The tracking problem can be reduced to applying the detector
        to each frame of video and outputting it's response \cite{Forsyth2012}.

        Certain situations lend themselves well to this approach, for example;
        One could imagine that an overhead camera in a game of billiards could
        easily track the position of the 8-ball by searching each video frame
        for the colour black, as this colour differs significantly from the
        green felt, and the colour of the other balls.
        
        However, many practical applications cannot assume reliable detection or
        single objects of interest. Referring back to the above example,
        difficulty may arise if a player is wearing a long sleeve black shirt as
        the detector would interpret this as the ball, such a scenario may
        require more sophistication in the design of the detector.

    \item Tracking Translation by Matching:
        Matching is based on the tendency for an object's appearance to be
        temporally similar and exhibit coherence in motion between successive
        frames.
        Given a model of an objects motion, as well a domain within a particular
        frame in which the object of interest is located. The motion model can
        be used to search for the domain of interest within a subsequent frame.
        \cite{Forsyth2012}
\end{itemize}   

The above approaches to the overall problem highlight two key subtasks:
    \begin{itemize}
        \item Object Detection: This is concerned with identifying whether an
            object, or multiple object's of interest is/are present within a
            given scenario.
        \item Object Tracking: This is concerned with successively following an
            identified objects of interest in one frame in subsequent frames in
            of a video or image sequence.  
    \end{itemize}
The relevant literature details numerous approaches to each of the above
subtasks of the overall Motion Tracking Task. Before elaborating on these
approaches, it is necessary to have an understanding of challenges faced in
the practical implementations of these subtasks.

\section{Challenges faced by Computer Vision}\label{literature_review_challenges}
Addressed here are several challenges faced when developing Computer
Vision Algorithms to solve the tasks of Object Detection and Motion Tracking. 
These ideas will be necessary in assessing which approaches to focus on within
this study, in line with the objectives outlined in Section~\ref{introduction_objectives}.

The challenges are conveniently expressed in
Table~\ref{tbl:computer_vision_challenges}. Experts of image sequences 
from the VOT2017~\cite{VOT_TPAMI} datasets are used to illustrate the various
challenges.

\begin{longtable}{ c  p{3cm}  p{4cm} }
    \hline
    \textbf{Illustration} & \textbf{Challenge} & \textbf{Description} \\ 
    \hline\hline
    \raisebox{-\totalheight}{\includegraphics[width=0.3\textwidth,height=40mm]{figures/logo.pdf}}
    &
    1. Occlusion
    & 
    Objects of interest may only be partially visible in a
    given frame, ideally we want an algorithm to still detect or
    track an object despite this.
    \\ \bottomrule
    
    %\raisebox{-\totalheight}{\includegraphics[width=0.3\textwidth, height=40mm]{images/myLboro.png}}
    &
    2. Illumination
    &
    Algorithm performance can be significantly degraded by changes
    in lighting, if their implementation does not take this into
    account.
    \\ \bottomrule

    %\raisebox{-\totalheight}{\includegraphics[width=0.3\textwidth, height=40mm]{images/myLboro.png}}
    &
    3. Ego Motion
    &
    If image sequences are not recorded by a stationary observer,
    the camera motion has to be accounted for by the algorithm.
    \\ \bottomrule
    
    %\raisebox{-\totalheight}{\includegraphics[width=0.3\textwidth, height=40mm]{images/myLboro.png}}
    &
    4. Deformation
    &
    between frame's. For example, observing a bird flying. In this
    case an algorithm may fail if it assumes a consistent shape for
    the object of interest.
    \\ \bottomrule

    %\raisebox{-\totalheight}{\includegraphics[width=0.3\textwidth, height=40mm]{images/myLboro.png}} 
    &
    5. Orientation
    &
    Objects look different according to their orientation relative
    to the camera.
    \\ \bottomrule

    %\raisebox{-\totalheight}{\includegraphics[width=0.3\textwidth, height=40mm]{images/myLboro.png}}
    &
    6. Scale
    &
    An object of interest may change it's scale within an image
    sequence, depending on whether it is moving away from or towards
    the observer.
    \\ \bottomrule

    %\raisebox{-\totalheight}{\includegraphics[width=0.3\textwidth, height=40mm]{images/myLboro.png}} 
    &
    7. Speed 
    &
    Many algorithms operates on the assumption of small
    changes of the position and appearance of an object between
    subsequent frames. An object moving at a high enough velocity
    affect the performance of algorithms that are not designed to
    deal with this.
    \\ \bottomrule
    \caption{Table illustrating Computer Vision Challenges}
    \label{tbl:computer_vision_challenges}
\end{longtable}

\section{Object Detection}
Object detection generally refers to the identification of objects within
an image. It is thereby a segmentation of the image into foreground
and background with foreground containing the object(s) of interest for subsequent
operations.

In the context of motion tracking, the problem of object detection is a key
step. It becomes narrowed down to the more specific task of motion segmentation.
The literature details several approaches to this task, summarised in 
Figure \ref{motion_detection_taxonomy} below.

\Figure[width=0.7\columnwidth]{Taxonomy of Motion Detection
Approaches\label{motion_detection_taxonomy}}{literaturereview_taxonomy_motion_detection}

*Explain Diagram

\section{Object Tracking}
Moving objects in a video have a state. A state can be directly observable such as a
particular object's colour features, or position in a frame. A state can also be a function
of observable states such as the object's velocity.

In Object Tracking, the state we are interested in is the position of an object
of interest in successive frames of video. We may use states or derivatives of
them to reliably determine this \cite{Forsyth2012}.

The literature states several approaches to the motion tracking problem. The can
conveniently be expressed in the following taxonomy, Figure \ref{motion_tracking_taxonomy},
adapted from Prajapati \cite{Prajapati2015}.

\Figure[width=0.7\columnwidth]{Taxonomy of Motion Tracking
Approaches\label{motion_tracking_taxonomy}}{literaturereview_taxonomy_motion_tracking}

*Explain Higher Level*

\subsubsection{Simple Template Matching}
Template Matching is a high-level Machine Vision operation that aims to determine
what elements of a given image match a specified template of the element of
interest.
Formally we have a source image, $I$ in which we would like to obtain matches to
an element of interest defined by a template image $T$.

\subsubsection{Mean-Shift} \label{literature_review_mean_shift}


\section{GUI Design}

\section{Software}

\subsection{Relevant Languages}

\subsection{Relevant Libraries}




