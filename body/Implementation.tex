\chapter{Implementation}\label{chapter_implementation}

This Chapter details the implementation of the relevant software modules of the
Overall MOT System. The work is firmly grounded within the Theoretical Framework
established in Chapter~\ref{chapter_theoretical_framework} and the System Design
developed in Chapter~\ref{chapter_design}. The Implementations documented here
are subsequently tested in Chapter~\ref{chapter_results}.

The focus of this Chapter is in the presentation of the algorithmic
implementation, independent of class structure. The reason behind this is so
that the parallels to the underlying theory in
Chapter~\ref{chapter_theoretical_framework} can better be appreciated.

The only differences between the class-based implementations according to the
UML Diagram in Figure~\ref{fig:design_uml} and those presented here, is that the
class functions do not always explicitly passed between functions but rather
through instance variables. 

\section{Colour Co-occurrence Histogram Detector}\label{implementation_ch}
The implementation of the CH-Detector follows directly from the algorithm
description in Section~\ref{theoretical_framework_ch}.

\subsection{Computing Model and Candidate CH's}
The model and candidate CH's are computed by separate functions. The reason for
this is that the 
Computing the model CH is implemented in the \textbf{get\_model\_CH (template,nc,nd)}
function this

\begin{lstlisting}[language=Python, caption={Computing model CH}, captionpos=b, label={lst:pdf}]
def get_model_CH(template, nc, nd):
    """computes overall CH along vertical and horizontal axes"""
    # step1: quantize rgb colourspace according to nc
    kmeans, q_labels2d = RGB_quantize_model(template, nc)
    
    # step2: compute vertical and horizontal CH's
    CH_v  = CH_vertical(q_labels2d, nc, nd) # compute vertical CH
    CH_h  = CH_horizontal(q_labels2d, nc, nd) # compute horizontal CH
    CH_pd = CH_pos_diagonal(q_labels2d, nc, nd) # compute positve diagonal CH
    CH_nd = CH_neg_diagonal(q_labels2d, nc, nd) # compute negative diagonal CH

    # step3: combine and return overall model CH
    return kmeans, np.sum((CH_v, CH_h, CH_pd, CH_nd), axis=0)
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={Computing candidate CH}, captionpos=b, label={lst:pdf}]
def get_candidate_CH(kmeans, template, nc, nd):
    """computes overall CH along vertical and horizontal axes"""
    # step1: quantize rgb colourspace according to nc
    q_labels2d = RGB_quantize_candidate(kmeans, template, nc)
    
    # step2: compute vertical and horizontal CH's
    CH_v  = CH_vertical(q_labels2d, nc, nd) # compute vertical CH
    CH_h  = CH_horizontal(q_labels2d, nc, nd) # compute horizontal CH
    CH_pd = CH_pos_diagonal(q_labels2d, nc, nd) # compute positve diagonal CH
    CH_nd = CH_neg_diagonal(q_labels2d, nc, nd) # compute negative diagonal CH

    # step3: combine and return overall candidate CH
    return np.sum((CH_v, CH_h, CH_pd, CH_nd), axis=0)
\end{lstlisting}


\subsection{Computing the Similarity Measure}


\section{Mean Shift Tracker}\label{implementation_mean_shift_tracker}
The implementation of the Mean Shift Tracker follows directly from the algorithm
description in Section~\ref{theoretical_framework_mean_shift_algorithm}.

This Section begins by laying out some preliminaries choices for the algorithm
implementation, then details the implementation of the various functions and
their overall integration into a working Mean Shift Tracker. The  

\subsection{Algorithm Parameters}
The Mean Shift Tracker has three parameters that can affect it's performance.
The maximum allowable mean shift step size (in pixels), $\epsilon$. The number
of bins used in computing our target and candidate pdf's $\hat{q}$ and
$\hat{p}$, and finally the size of the Kernel initialised around the target
object.
An implementation should allow for variations of these parameters.

\subsection{Computing Target and Candidate pdfs}
Computing a pdf for a particular region of interest according to 
Equation~\ref{eqn:mean_shift_histogram} is performed by the \textbf{get\_pdf
(template, m)} method shown in Listing~\ref{lst:pdf}.

\begin{lstlisting}[language=Python, caption={Computing pdf}, captionpos=b, label={lst:pdf}]
def get_pdf(template,m=8):
    """compute 2d colour histogram given template,bin number,m and kernel function"""
    # step1: limit pixels to elliptical region inscribed in rectangle
    height, width = template.shape[0], template.shape[1]
    y0, x0 = (height//2, width//2) # get center of kernel (treated as 0,0) == hy and hx 
    elliptical_mask = get_elliptical_mask(height, width)
       
    # step2: fetch pixel values
    hist = np.zeros(shape=(m, m)) # 2d-histogram to hold values 
    kernel, C = get_epanechnikov_kernel(template) # kernel and normalisation constant, C
    for y in range(0,height):
        for x in range(0,width): 
            if(elliptical_mask[y,x]==True): # only deal with points in the mask
                u, v = int((template[y,x,0]/256)*m),
                int((template[y,x,1]/256)*m) # get quantized R, G
                index_r, index_g = u//m, v//m # used to index 2d-histogram
                hist[index_r,index_g] = hist[index_r,index_g] + kernel[y,x] # add weighted point
    
    C = np.sum(hist) # normalisation constant
    histogram = np.true_divide(hist, C) # normalise histogram
    return histogram 
\end{lstlisting}

This above method is dependent on the implementation of the following support
methods. See Appendix~\ref{appendix_A} for code listings of their implementation.
\begin{itemize}
    \item get\_elliptical\_mask (height, width)
    \item get\_euclidean\_distance (x1, x2):
    \item get\_epanechnikov\_weight (x):
    \item get\_epanechnikov\_kernel (roi):
    \item get\_pdf (roi, m):
\end{itemize}

\subsection{Computing Bhattacharyyaa Coefficient}
Computing the Bhattacharyyaa coefficient between two pdfs is implemented in
Listing~\ref{lst:BC} according to Equation~\ref{eqn:bhattacharyya}. 

\begin{lstlisting}[language=Python, caption={Computing Bhattacharyya Coefficient}, captionpos=b, label={lst:BC}]
def bhatt_coeff(q, p):
    """compute the bhattacharyya coefficient between two 2D pdfs """
    height, width = q.shape[0], q.shape[1]
    batt = 0
    for y in range(0,height):
        for x in range(0,width):
            batt = batt + np.sqrt(q[y,x]*p[y,x])
    return batt
\end{lstlisting}

\subsection{Computing pixel weights}
Computing the pixel weights within the region of interest is performed by the
method \textbf{get\_weights (roi, q, p, m=8)} in Listing~\ref{lst:weights} according to Equation~\ref{eqn:mean_shift_weights}.

\begin{lstlisting}[language=Python, caption={Computing Mean Shift Weights}, captionpos=b, label={lst:weights}]
def pixel_weights(template, q, p, m=8):
    """compute the weights necessary for the mean shift algorithm given q and p"""
    # step1: limit pixels to elliptical region inscribed in rectangle
    height, width = template.shape[0],template.shape[1]
    y0, x0 = (height//2, width//2) # get centre 
    elliptical_mask = get_elliptical_mask(height, width)
    
    # step2: compute weights
    weights = np.zeros(shape=(height,width))
    for y in range(0,height):
        for x in range(0,width): 
            if(elliptical_mask[y,x]==True):  
                u, v = template[y,x,0], template[y,x,1] # get colour index, u 
                index_r, index_g = u//m, v//m # used to index 2d-histogram
                if(p[index_r,index_g]>0): # stop infinity division
                    weights[y,x] = np.sqrt(q[index_r,index_g]/p[index_r,index_g]) # comp weight
    return weights 
\end{lstlisting}

The implementation of listing~\ref{lst:weights} requires the following methods to
be available. See Appendix~\ref{appendix_A} for code listings of their implementation. 
\begin{itemize}
    \item get\_elliptical\_mask (height, width)
\end{itemize}

\subsection{Computing Mean Shift Vector}
Computing of the Mean Shift Vector is implemented in Listing~\ref{lst:msv}
according to %Equation~\ref{eqn:mean_shift_vector}.

\begin{lstlisting}[language=Python, caption={Computing Mean Shift Vector}, captionpos=b, label={lst:msv}]
def mean_shift(template, weights):
    """compute the mean shift vector of the template based on the weights"""
    # step1: limit pixels to elliptical region inscribed in rectangle
    height, width = template.shape[0], template.shape[1]
    y0, x0 = (height//2, width//2) # get centre 
    elliptical_mask = get_elliptical_mask(height,width)

    # step2: estimate shift vector
    v_y,v_x = 0,0 # to hold estimated shift vector
    for y in range(0,height):
        for x in range(0,width): 
            if(elliptical_mask[y,x]==True):
                v_y = v_y + weights[y,x]*((y-y0)) 
                v_x = v_x + weights[y,x]*((x-x0))
    w_sum = np.sum(weights) # compute denominator of expression
    if(w_sum!=0):
        return int(v_y/w_sum),int(v_x/w_sum) # return (vy, vx)
    else:
        return 0,0 # return no shift
\end{lstlisting}

The implementation of Listing~\ref{lst:vector} requires the following methods to
be available. See Appendix~\ref{appendix_A} for code listings of their implementation. 
\begin{itemize}
    \item get\_elliptical\_mask (roi)
\end{itemize}

\subsection{Performing the Mean Shift Loop}
The Mean Shift Loop is outlined by the Algorithm in
Figure~\ref{fig:mean_shift_tracking_algorithm}, the mean shift loop is
applied to a frame $\mathbf{f}_{k+1}$ given the model pdf of the object of
interest $\hat{q}$ and its location $\mathbf{c_0}$ in the previous frame
$\mathbf{f}_{k}$, to compute it's current position $\mathbf{c_1}$ in
$\mathbf{f}_{k+1}$

\begin{lstlisting}[language=Python, caption={Mean Shift Loop}, captionpos=b, label={lst:loop}]
def mean_shift_loop(frame, q, y0, x0, h, w, eps=5, m=8):
    """perform mean shift to get new location"""
    t1 = frame[y0:y0+h,x0:x0+w] # candidate template
    p0 = histogram(t1, m) # candidate histogram

    for i in range(0,10): # mean shift loop 20 iterations
        weights = get_pixel_weights(t1, q, p0, m) # calculate weights
        vy, vx = mean_shift(t1, weights) # calculate mean shift vector
        y1, x1 = int(y0+vy), int(x0+vx) # y1

        step_size = euclidean_distance((vy,vx),(0,0))
        if(step_size<eps): # likely to converge so check last
            return y1, x1 # found target object
            
        else: # step not small enough use battacharyya coefficient to refine step
            tc = frame[y1:y1+h,x1:x1+w] # get ROI at x1
            p1 = histogram(tc,m) # compute p(x1)
            batt0 = bhatt_coeff(q,p0) # similarity measure between q(x0) and p(x0) 
            batt1 = bhatt_coeff(q,p1) # similiarty measure betweem q(x0) and p(x1)

            while(batt0>batt1): # need to be better than origin rho
                vy, vx = vy//2, vx//2 # halve the step size
                y1, x1 = int(y0+vy), int(x0+vx) # get new smaller distance 
                tc = frame[y1:y1+h,x1:x1+w]
                p1 = histogram(tc, m)
                batt1 = bhatt_coeff(q, p1)
                if(np.abs(vy)<=1 and np.abs(vx)<=1): # avoid infinite loop
                    break
            return y1, x1
    return y1, x1
\end{lstlisting}

The implementation of the Mean Shift Loop in Listing~\ref{lst:loop} 
\begin{itemize}
    \item get\_pdf (roi, m)
    \item get\_weights (roi, q, p)
    \item get\_euclidean\_distance (x1, x2)
    \item get\_msv (roi, pixel\_weights)
    \item get\_BC (q, p)
\end{itemize}


\section{Graphical User Interface Implementation}
This Section deals with the Front-End implementation of the MOT system which is
in form of a GUI implemented by use of the pyQt5 python3 library.

The layout of the Layout follows the closely that of the mockup in
Figure~\ref{fig:design_gui_mockup}



