\chapter{Design}\label{design}
*insert summary of section content and structure*

\section{System Level Design}
Development of the overall system design can conveniently be divided into
Front-End and Back-End. The Front-End system is the point of interaction for the
system user. It is GUI application that thereby satisfying the User Requirements
of the system. The Back-End consists of the algorithms enabling the tracking of
objects of interest within video, thereby addressing the Technical
Specifications of the system.

The Overall System Design is summarised by the Block Diagram in Figure
\ref{motion_tracking_subtasks}.

\Figure[width=0.8\columnwidth]{Block Diagram of System Overview\label{motion_tracking_subtasks}}{design_system_overview}

\section{User Requirements}
The end-user requirements of the proposed system are elaborated upon below:
\begin{itemize}
    \item The GUI application should have a menu that allows for a system
        user to select a video or image sequence of interest.
    \item Upon the selection of an image sequence, the system will allow for a
        user to specify an object or point of interest within the first sequence
        frame for tracking in subsequent frames.
    \item The system should reliably output a bounding box around the user
        specified point or object of interest in subsequent frames of the
        sequence. 
    \item At termination of the sequence, snapshots of the bounding box
        surrounding the relevant point of interest or object should be stored in
        a user selected directory.
    \item
    \item 
\end{itemize}

\section{Specification}
This section aims to present functional specifications, set out in the
project brief.

\subsection{Environmental Requirements}


\subsection{Non-functional Requirements}


\subsection{Feature Specifications}


\subsection{Use Cases}


This following Section are concerned with the detailed design of of the Front- and Back-end
subsystems of the Motion Tracking System.

\section{Front-End Design}
The Front-End is the GUI that user's of the Motion Tracking System interact with 
It interacts with the underlying functionality implemented in the Back-End to
satisfy the System User Requirements. 

\section{Back-End Design}
As indicated by the indicated by the literature in Section
\ref{literature_review_general_approach}. Three variants of kernel based object
trackers were implemented.

\subsection{Template Matching Tracker}

\subsubsection{Simple Template Tracking}

\subsubsection{Adaptive Template Tracking}


\subsection{Mean Shift Tracker}
As summarised in section \ref{literature_review_mean_shift}, the Mean Shift Tracker was
first proposed by Commaniciu et al. It is addresses the
visual tracking problem of Target Representation and Localization.

The idea of this tracker is that spatially masking an object with an
isotropic kernel allows for the definition of a spatially-smooth similarity
function between a target and potential candidate model. This smooth similarity
allows for gradient-based optimization in achieving target localisation in
subsequent frames \cite{Comaniciu2003}.

A description of theory underlying the Mean Shift Tracker follows:

\subsubsection{Target and Candidate Representation}
To represent a particular target or candidate Model, a suitable feature space
must be chosen. The choices could be anything from grayscale intensity, RGB
intensity or Texture of the particular object. Objects geometrically described 
as elliptical sub-domains $\mathbf{D}$ of a frame, with dimensions $h_x$ and
$h_y$ and center $\mathbf{x}$.

Target and candidate models are defined as pdf's within the chosen feature
space defined over $\mathbf{D}$. In the initial frame, $\mathbf{f}_k$, a target
model of the object to be tracked located at $\mathbf{x_0}$ is defined by it's
pdf, $\hat{q}(\mathbf{x_0})$. In the subsequent frame, $\mathbf{f_{k+1}}$, a
candidate model is defined with pdf $\hat{p}(\mathbf{x_0})$ starting at the last
known object position $\mathbf{x_0}$. 

Both pdf's $\hat{q}(\mathbf{x_0})$ and $\hat{p}(\mathbf{x_0})$ are estimated from
their respective frames $\mathbf{f}_k$ and $\mathbf{f}_{k+1}$ using $m$-bin
histograms in the relevant feature space. Depending on the number of
features used computational complexity of calculating the histogram and space
needed for storing the histogram goes up by a factor of $m$, as we are
increasing the dimensionality of our feature space by 1 for each additional
feature thus incrementing the size by a factor of $m$-bins.

The models for the target and candidate are summarised below:
$$\text{target model: } \hat{q}(\mathbf{x_0})=\{\hat{q}_u(\mathbf{x_0})\}_{u=1,...,m}$$
$$\text{candidate model: } \hat{p}(\mathbf{x_i})=\{\hat{p}_u(\mathbf{x_i})\}_{u=1,...,m}$$

All model/candidate histograms are normalized. Therefore, a general m-bin
histogram, $\hat{p}(\mathbf{x_i})$ defined over spacial sub-domain, $\mathbf{D}$
within a frame $\mathbf{f}_k$, satisfies the following normalisation condition:
\begin{equation}\label{eqn_histogram_normalisation}
    \sum_{u=1}^{m}\hat{p}_u = 1
\end{equation}

Computing the histogram occurs according to the following equation:
\begin{equation}
    pdf(u)=C\sum_{i=1}^{n_x}\kappa({\parallel{\mathbf{x_i}^*}-{\mathbf{x_0}^*}\parallel}^2)\delta[b(\mathbf{x_i}^*)-u]    
\end{equation}
\begin{equation}
    C=\frac{1}{\sum_{i=1}^{n_x}\kappa({\parallel\mathbf{x_i}^*\parallel}^2)}
\end{equation}
where:
\begin{itemize}
    \item $\parallel{\mathbf{x_i}}^*-{\mathbf{x_0}}^*\parallel$: The euclidean
        norm between $\mathbf{x_i}^*$ and ${\mathbf{x_0}}^*$ squared which
        reduces to $\parallel{\mathbf{x_i}}^*\parallel$ for $\mathbf{x_0} = 0$. 
    \item $\kappa({\parallel{\mathbf{x_i}}^*\parallel}^2)$: Kernel function that
        defining weights based on $\parallel{\mathbf{x_i}}^*\parallel^2$.
    \item $b({\mathbf{x_i}}^*)$: A function which maps the normalized pixel
        values in $\mathbf{n_x}$ to their RGB pixel value in $\mathbf{D}$.
    \item $\delta[b({\mathbf{x_i}}^*)-u]$: Assigns pixel value or a particular
        point in normalised kernel to appropriate bin u.
    \item $C$: Normalisation constant to ensure histogram satisfies equation
        \ref{eqn_histogram_normalisation}.
\end{itemize}

\subsubsection{Kernel Profile $\Kappa(x)$: Epanechnikov Kernel}
A Kernel is a weighting function employed in non-parametric density estimation. 

The recommended kernel function for the mean shift tracker is that of the
Epanechnikov Kernel.

The Epanechnikov Kernel has the following general equation:
\begin{equation}
    \kappa(x)=\frac{1}{2 c_d}(d+2)(1-x), |x|<1
\end{equation}
where:
\begin{itemize}
   \item $d$: the dimensions of the kernel
   \item $c_d$: the area of a unit circle in the dimension $d$
   \item $x$: the square of the Euclidian distance of the normalized pixel from $\mathbf{D}$
\end{itemize}

Of interest is the 2D variant of this equation given that the spatial smoothing
is occurring in the 2D $(x,y)$ pixel plane. Thus we choose $d=2$ and $c_d=\pi$.
As the kernel profile does not vary for a particular region of interest, it is
computationally convenient to pre-calculate its values for use in the subsequent
derivation of the subsequent histogram

The calculation of the Epanechnikov Kernel Matrix for a particular $\mathbf{D}$ is
illustrated in Figure \ref{epanechnikov_kernel}.

\Figure[width=0.8\columnwidth]{Illustration of Epanechnikov Matrix Derivation\label{epanechnikov_kernel}}{design_epanechnikov_kernel_illustration}

The pixels in the elliptical mask of the target/candidate are normalized to a unit
circle by scaling the ellipse by $h_y$ and $h_x$ (which are the major and minor
axes size of the ellipse). Each pixel is then assigned a weight according to the
value of the 2D Epanechnikov Kernel for said pixel's normalized euclidean
distance from the unit circle centre as illustrated in Figure \ref{epanechnikov_kernel}.

\subsubsection{Similarity Measure, $\rho$: Bhattacharyya Coefficient}

$\rho(y) \equiv \rho[\hat{p}(y),\hat{q}]$
Given a target model's pdf of $\hat{q}$, and a candidate pdf in a subsequent
frame $\hat{p}(y)$.  The function $\rho(y)$ tell us how strongly a candidate pdf
$\hat{p}(y)$ resembles the target pdf $\hat{q}$. In our application, pdf
$\hat{q}$ is determined in frame $n-1$ and the target pdf(s) are drawn from
frame $n$ in which we would like to determine how the object has moved

As per \cite{Comaniciu2003} we make use of the Bhattacharyya coefficient, $BC$ as our
measure of similarity $\rho$ between the target and candidate pdfs, which is
defined as
\begin{equation}
    BC = \rho[\hat{p}(y),\hat{q}]=\sum_{u=1}^{m}\sqrt{\hat{p}_u(y)\hat{q}_u}
\end{equation}

\subsubsection{The General Algorithm}
The general algorithm for Mean Shift Tracking between two frames is defined by
flow chart in Figure \ref{mean_shift_tracking_algorithm}. 

\Figure[width=0.7\columnwidth]{Flow Chart of Mean Shift Tracking Algorithm
between two frames $\mathbf{f}_k$ and
$\mathbf{f}_{k+1}$\label{mean_shift_tracking_algorithm}}{design_mean_shift_tracking_algorithm}

\subsection{Development Environment and Tech-Stack}
This section details underlying Tech-Stack of the Motion Tracking System. The
purpose of this section is to ensure easy reproducibility of the implemented
system.

\subsubsection{}

\section{Integration Design}
This section details the specifics of how 





